%!TEX root=../thesis.tex
\chapter{Real-Time background} \label{cha:rt_background}

The work described in this thesis has many theoretical foundations that has to be
clear in order to understand the reasons behind some of the design choiches and
assumptions. All the needed notions in the real-time theory are explained in the
following sections.


\section{Task model} \label{sec:task_model}
This model considers a set of real-time tasks \( T = \{\tau_{i}\} \)
sharing a Central Processing Unit (CPU). Every task
is composed of a stream of jobs \( J_{i,\,k} \) identifying the \( k^{th} \)
instance of the \( i^{th} \) task in the set \( T \). The concept of multiple
jobs composing a task can be better understood looking at Figure \ref{img:task_model}.
\begin{figure}[!htb]
    \center{\includegraphics[width=0.7\linewidth]{task_model.png}}
    \caption{A graphical explanation of the task model.}
    \label{img:task_model}
\end{figure}

Every job is formally defined as a touple
\( J_{i,\,k} = \left(r_{i,\,k}, \;f_{i,\,k}, \;c_{i,\,k}\right) \) where:
\begin{itemize}
    \item the subscript \( i \) specifies the number of the task inside the task 
        set \( T \)
    \item the subscript \( k \) specifies the instance of the job belonging to
        the \( i^{th} \) task
    \item \( r_{i,\,k} \) is the \emph{release} time; it is the time when
        the job arrives to the scheduler and it can be chosen for execution
        by the system (and actually taken in charge by the CPU). In Figure
        \ref{img:task_model} it is represented by the down arrows along the
        timeline.
    \item \( f_{i,\,k} \) is the \emph{finishing} time; it is the instant when
        the computation for the job \( J_{i,\,k} \) ends.
    \item \( c_{i,\,k} \) is the \emph{computation} time; it is the amount of
        time for which the job \( J_{i,\,k} \) is running. This can also be seen
        as the real load on the CPU, that is symbolized by the rectangles
        in Figure \ref{img:task_model}.
\end{itemize} 

In addition, the computation time \( c_{i,\,k} \) is generally assumed to be an
independent and identically distributed (i.i.d.) stochastic process.
This happens when two random variables \( X \) and \( Y \) have 
the same probability distribution and both are mutually
independent, meaning that the occurrence of \( X \) does not interfere with 
the probability of occurrence of \( Y \) (and vice versa).
Hence, for each job instance, \( c_{i,\,k} \) is a random
variable described by a certain Probability Mass Function (PMF) since it
takes values in the discrete field.
The i.i.d. assumption is one of the milestones of the real-time modeling theory.
However, the analysis proposed in Chapter \ref{cha:rt_model} will relax this 
constraint following the study proposed by Fr\'{i}as et al
in~\cite{frias2017probabilistic}, where a novel mathematical model is applied
in order to describe computation times that are not following the i.i.d.
assumption.

Another very important concept is the worst-case execution time (WCET).
It represents the upper bound for the fraction of CPU time spent to execute a task
\( \tau_{i} \) and it can be computed using the following equation:
\begin{equation}\label{eq:wcet}
    W_{i} = \ceil[\bigg]{\frac{c_{i,\,j}}{T_{i}}}
\end{equation}

Computing the WCET value may involve statistical testing~\cite{bernat2002wcet}
and, in some case, also formal verification~\cite{souyris2009formal} of the
software under test.
Moreover, the total system utilization \( W_{tot} \) can be easily derived from
Equation \ref{eq:wcet} as:
\begin{equation}\label{eq:system_utilization}
    W_{tot} = \displaystyle\sum_{i} W_{i}
\end{equation}

Furthermore, every real-time job has to respect a temporal constraint called
deadline. The standard approach is to have a deterministic deadline for a job
that cannot be missed (hard real-time), but other models handles also
less strict and probabilistic deadlines (soft real-time).
More formally, every job \( J_{i,\,k} \) has a relative deadline \( D_{i} \) that
is used to define an absolute deadline \( d_{i,\,k} \) as follows:
\begin{equation}
    d_{i,\,k} = r_{i,\,k} + D_{i}
\end{equation}

Such deadline is said to be respected if \( f_{i,\,k} \leq d_{i,\,k} \) and missed
if \( f_{i,\,k} > d_{i,\,k} \). Talking about probabilistic deadlines, it is
possible to say that a deadline is respected if 
\( \Pr\,\{f_{i,\,k} > r_{i,\,k} + D_{i} \} \leq p_{i} \) and it is missed otherwise.
In this case, the value \( p_{i} \) is the probability to meet the deadline associated
with the task \( \tau_{i} \).


\section{Different types of tasks}
Not all the real-time tasks are equal. The different types existing in
the literature are \emph{periodic}, \emph{aperiodic} and \emph{sporadic}.

A periodic task has regular structure
and it is triggered every fixed period \( T_{i} \). Its lifetime can be seen as
a cycle, where it activates at time \( r_{i,\,k} \), it executes for an amount 
of time \( c_{i,\,k} \) and then it waits for the next period to start again.
The loop exit condition depends on the specific application.\\
On the contrary, as the name suggests, an aperiodic task has non-periodic arrivals.
Moreover there is no minimum inter-arrival time between the jobs and,
most of the times, these tasks do not have any recurrent structure. They are used
to model operations occurring rarely and that are irregular during the lifetime
of the whole system.\\
Finally, the sporadic task is very similar to the periodic one. Both have a minimun
inter-arrival time between each activation, even though it may not be always the
same throughout the entire execution. A sporadic task is mainly triggered by an
external event (eg. a network packet) instead of using a timer.


\section{Scheduler} \label{sec:scheduler}
As it is possible to imagine, tasks do not run on bare hardware.
The Operating System (OS) creates the illusion that each task has a virtual CPU
where they run alone without any interference from the others.
This strategy makes them believe that they are running simultaneously on the same
machine. This statement is true if we think of a single CPU with one core. Modern
CPUs are multi-core and they give the possibility to actually run multiple tasks
at the same time. The general rule is that the number of process that can be
executed in parallel is upper-bounded by the number of available physical cores.
For the sake of simplicity it is reasonable to assume that a CPU has only one core.\\
Since it is possible to run only one task at a time on a single CPU, they need
to alternate each other in order to give everyone the possibility to get their
work done. Here is where the task scheduler, which is responsible for
scheduling a set of tasks, starts its job.

There exist several scheduling algorithms that can be used to select which task 
has to be executed at every instant \emph{t}. More in general, it is
possible to say that a scheduling algorithm \emph{A} generates a schedule
\( \sigma_{A}\left(t\right) \) starting from a set of tasks \( T = \{\tau_{i}\} \).
Furthermore, a schedulability test can be performed to see if the scheduling
algorithm \( A \) is able to schedule a given task set \( T \). This checks
if the schedule \( \sigma_{A}\left(t\right) \) generated by the algorithm \emph{A}
guarantees that every deadline (probabilistic or not) is never missed.

Some of the most famous scheduling algorithms in the computer science literature
are Rate Monotonic (RM)~\cite{lehoczky1989rate}, Deadline Monotonic
(DM)~\cite{audsley1991hard} and Earliest Deadline First (EDF)~\cite{jansen2003lightweight}.
Another well known approach is the so called \emph{sched\_deadline}~\cite{lelli2016deadline}
algorithm, which is available in the mainline Linux kernel as scheduling algorithm
from the 3.14 version.


\section{Resource Reservation scheduling}
As stated in Section \ref{sec:scheduler}, modern multi-core CPUs allow multiple
tasks to run concurrently. Thus, there esists another approach to the schedulability
problem.

The resource reservation (RR)~\cite{abeni1998integrating} algorithm allows to associate to each task 
\( \tau_{i} \) a reservation \( \left(Q_{i}^s, T_{i}^s\right) \). 
This algorithm allows the \( i^{th} \) task to only run for \( Q_{i}^s \) time units 
in every interval of length \( T_{i}^s \). The value \( Q_{i}^s \) is defined as
budget, while \( T_{i}^s \) is known as the reservation period.
This approach allows to allocate a fraction of CPU time for a task \( \tau_{i} \)
called bandwidth and it is calculated as follows:
\begin{equation}
    B_{i} = \frac{Q_{i}^s}{T_{i}^s}
\end{equation}

In this way the scheduler reserves for each task an amount of computation
time \( Q_{i}^s \) in each reservation period \( T_{i}^s \). This constraint
prevents tasks from running for more time than the selected budget and
therefore each task does not need to pay attention to the other tasks running
concurrently on the same CPU. This very important property for RR algorithm is called
\textbf{temporal isolation} and it is valid as long as the scheduling
condition~\cite{lee2007handbook} shown in Equation \ref{eq:temporal_isolation} 
holds.
\begin{equation} \label{eq:temporal_isolation}
    \displaystyle\sum_{i} B_{i} =  \displaystyle\sum_{i} \frac{Q_{i}^s}{T_{i}^s} \leq 1
\end{equation}

Temporal isolation allows the system designer to analyze every
task on its own, making its life much easier.


\section{Hard vs. soft real-time}
First of all, real time processing should not be confused with ``fast''. The notion
of speed highly depends on the specific application. Real time systems focus on
giving deterministic and predictable response times, quantifying the worst-case
scenario and being prepared to handle it properly.

As previously mentioned in Section \ref{sec:task_model}, there exist two different
notions of real-time.\\
In hard real-time systems every deadline must be respected, meaning
that even a single dealine miss implies a system failure. This is the case, for
example, of some medical applications like pacemakers and some avionics systems
where many people's lives are in danger if such systems fail. To achieve such
reliability, enhanced real-time OS kernels have to be used, since they are proved
to guarantee a 100\% precision on the WCET value. Even a 99,9\% precision is not
enough in this case. ``Safety-critical'' systems is a concept that often goes
together with the one of hard real-time, where strict temporal guarantees are
mixed with functional safety concepts in the industry sector. A trivial but clear
example is that nobody wants a sensor to fail in a car braking system while
it is being used.\\
On the other hand, the requirements for soft real-time systems are looser. This
means that it is acceptable to miss some deadline.
This is what happens in streaming video players for example, where missing the
deadline for some frame may not even noticed by the user. Clearly, if too many
frames are not displayed on the screen the streaming cannot be enjoyed by the
user in any way. Another notheworthy aspect is that if a soft real-time system
misses some deadline no critical failure happens and no life is put in danger.
Obviously this is clearly not the case for the other ones, where a disaster
maight happen only due to a single deadline miss in the entire system.\\
Focusing on the work of this thesis, the 3D navigator has been also developed 
to study how
real-time models can be applied to web technologies and, more specifically, to
WebGL. This case study is obviously a soft real-time application, since
no life is put in danger and no critical system fails because of this part of
the FriWalk architecture.
