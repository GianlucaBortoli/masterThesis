%!TEX root=../thesis.tex
\chapter{Experiments} \label{cha:experiments}

This chapter outlines all the methodologies used to analyze the test application
and it provides a discussion of the outcomes.


\section{First measurements}\label{sec:first_measurements}
The first step to outline the behaviour of the test application is to include
the the Web Tracing Framework library and to place
the proper functions as shown in Listing \ref{code:wtf_example}.
Consequently, the first measurements are obtained following the metodologies
explained in Sections \ref{sec:assumptions} and \ref{sec:procedure}.

This very first approach can be considered as an
exploratory phase. If all the default events available to the WTF are used, the
resulting trace contains a considerable amount of data. Fortunately there is a
graphical interface that allows to easily navigate the hierarchical structure
of the function calls inside the trace. After getting used to the tool and its
data format, a selection of the interesting function calls is outlined in order
to narrow the search field only to WebGL functions. The resulting list of primitives
is presented in Table \ref{tab:webgl_function_list}.
\begin{table}[!htb]
    \centering
    \caption{The list of the WebGL function of interest.}
    \label{tab:webgl_function_list}
    \begin{tabular}{|lllll|}
        \hline
        bindBuffer    & viewport        & clearColor    & bindTexture & uniformMatrix4v \\
        bufferSubData & clear           & createTexture & pixelStorei & linkProgram     \\
        disable       & bindFrameBuffer & activeTexture & textImage2D & \\
        \hline                
    \end{tabular}
\end{table}

After some test, the trace extracted from the ``no-map'' scenario
is selected as the first to be analyzed in detail. This choice is made
to clarify the potential of the framework and to understand its limits, since
this is the basic building block used in the rest of the work.
Profiling the navigator in the abovementioned scenario outputs a trace that
illustrates a very interesting result. Figure \ref{img:no_map_overview}
shows a timeline representation of the trace, where every colored vertical bar
symbolizes the occurrence of a function call or an event tracked by the tool.
As it is possible to notice, all of them are arranged into fairly regular groups.
\begin{figure}[!htb]
    \center{\includegraphics[width=1\linewidth]{no_map_overview.png}}
    \caption{An example trace highlighting the function groups.}
    \label{img:no_map_overview}
\end{figure}

Furthermore, it turns out that every group always start with a \emph{bindBuffer}
call. According to the WebGL official documentation\footnote{A detailed description
of the WebGL APIs can be found at the following link:
\url{https://developer.mozilla.org/it/docs/Web/API/WebGL_API}.}, this function is
responsible for binding a buffer object containing vertexes and/or colors to the
current WebGL context. Essentially it marks an arbitrary buffer to be the current
one where all the other WebGL functions will work on. This is necessary due to the
inability of the GPU process to deal with more than one data structure at a time. Hence,
it is possible to virtually split the trace into small groups by means of the
\emph{bindBuffer} function.

After identifying the particular structure of the trace, it is possible to check
which are the recurrent WebGL functions belonging to each group and to gather them into
macro-operations sets. After checking which is the specific task fulfilled by every
function, it became clear that they belong to three main scopes:
\begin{itemize}
    \item \emph{initialization/load data}: every WebGL function in this group
        is responsible for preparing the data structures to be loaded in memory
        and for copying all the needed data (eg. copies the bitmap of a texture
        into some buffer).
    \item \emph{modify data}: these functions actually work on the vertex/color
        buffer to modify the data, especially via matrix operations (eg. updates
        the value for a subset of objects in the buffer).
    \item \emph{display/draw}: this group is the one that sends the commands
        that are actually used by the GPU to draw the shapes on the screen
        (eg. renders the vertexes in the buffer array).
\end{itemize}

A more detailed functions-to-groups mapping is shown in Table
\ref{tab:webgl_func_mapping}.

\begin{table}[!htb]
    \centering
    \caption{WebGL functions-to-groups mapping.}
    \label{tab:webgl_func_mapping}
    \begin{tabular}{|l|l|l|}
        \hline
        \textbf{Initialization/load data} & \textbf{Modify data} & \textbf{Display/draw} \\ \hline
        bindBuffer/bindFramebuffer & uniformMatrix3fv/uniformMatrix4fv & drawElements \\
        enable/disable & uniform[1\(\vert\)2\(\vert\)3\(\vert\)4][f\(\vert\)i\(\vert\)iv\(\vert\)fv] & drawArrays \\
        viewport & bindTexture/activeTexture &  \\
        clear/clearColor & bufferSubData &  \\
        cullFace &  &  \\
        depthCompare &  &  \\
        useProgram &  &  \\
        colorMask &  &  \\
        \hline
    \end{tabular}
\end{table}

Another important aspect is how the timings' values fluctuate during every run of
the application. As it is possible to see from Figure \ref{img:no_map_example},
there can be outliers where the response time is significantly larger with respect
to all the rest of the trace.
\begin{figure}[!htb]
    \center{\includegraphics[width=0.75\linewidth]{500ms_1_no_map.png}}
    \caption{A trace extracted from the ``no-map'' scenario.}
    \label{img:no_map_example}
\end{figure}

This fluctuating trend can have several justifications which need to be investigated
further. Since the WTF is able to measure only the response times of the application
with a precision of \(\pm 0.5\,ms\), the bar chart shown in Figure
\ref{img:no_map_example} displays a composite value on the Y axis. The response
time can be computed as follows:
\begin{equation}
    response\_time = computation\_time + interference
    \label{eq:response_time}
\end{equation}

The \emph{interference} component is clearly due to the huge operating system
stack lying between the JavaScript code, running inside the
browser, and the Mesa 3D graphics driver, which is part of the Linux OS kernel.
Hence, this inconvenience needs to be reduced as much as possible in order not to jeopardize the
validity of all the results presented in this chapter. One possibility to mitigate
the interference from higher priority tasks is to increase that of
the Googhe Chrome instance using the \emph{nice} tool~\cite{aas2005understanding}.
Another approach includes to directly change the scheduling policy via the
\emph{chrt}\footnote{\url{http://man7.org/linux/man-pages/man1/chrt.1.html}.}
utility for using a different scheduling algorithm. After several attempts,
it is possible to state that no
noteworthy difference in the response times can be observed after applying these
methods. For this reason, further investigations in the \emph{computation\_time}
component are foundamental for the timings fluctuations.

Moreover, after dividing all the WebGL functions into macro-operations groups
(see Table \ref{tab:webgl_func_mapping}) it is possible to refine the graph shown
in Figure \ref{img:no_map_example}. As it is possible to see from Figure
\ref{img:no_map_groups}, this ``grouped'' bar chart is very useful to understand
the weight of every set of operations with respect to the time elapsed between
each \emph{bindBuffer} function call.
\begin{figure}[!htb]
    \center{\includegraphics[width=0.8\linewidth]{500ms_1_no_map_groups.png}}
    \caption{An example of a grouped bar chart computed from a trace.}
    \label{img:no_map_groups}
\end{figure}

Finally, a comparison between extensive 2D and 3D tests showed that response times
during 3D rendering are slightly higher and more prone to fluctuations. This is
certainly due to the different computation workloads which can significantly change
over time, depending on the complexity of the scene to be rendered.
This analysis using the WTF allows to discover an approximate task model, where
each job of the rendering task can be divided into three logically different
parts. This can be summarized as shown in Figure \ref{img:call_arrival}.

\begin{figure}[!htb]
    \center{\includegraphics[width=0.6\linewidth]{call_arrival.png}}
    \caption{The function calls arrival approximate model with the different groups.}
    \label{img:call_arrival}
\end{figure}


\section{A fine-grained model}
Some other approach is needed to get better insights with respect to the ones
presented in the previous chapter. The first issue to be adressed is that the
WTF framework is able to retrieve only response times (see Equation
\ref{eq:response_time}). Usually real-time models deal with computation times
rather than response ones. Hence, the problem of measuring exact computation
times without the interference coming from other tasks becomes a strict requirement.
Another important aspect is the resolution of the timings. As stated in Section
\ref{sec:first_measurements}, the WTF framwork is able to extract times with a
0.5 milliseconds precision and this is clearly not enough for applying any of
the real-time mathematical models.
Last but not least, a more fine-grained view of the function calls involved in
the rendering process is needed. Furthermore, this allows to focus only on the
``\emph{display/draw}'' group presented in Table \ref{tab:webgl_func_mapping}
without restricting the analysis only to the \emph{drawElements} and
\emph{drawArrays} functions found by the web tracing framework.

It immediately become clear that the tool presented in Section \ref{sec:first_measurements}
is not powerful enough to recognize what is happening inside the browser internals.
The tool that perfectly fits these requirements is the Trace Event Profiling
Tool~\cite{eventprofilertool} embedded into the Chrome web browser.\\
It allows to capture computation times (and not only response times) of multiple
events including the ones fired by the GPU process. Being able to distinguish
the \emph{computation\_time} from the \emph{interference} component is the key
that permits to apply mathematical models that would not be possible otherwise.
The profiler enables to captures the ``duration events'' of the commands received by the GPU
process from a server-side point of view (and not from the renderer client perspective).
Moreover it achieves more precise timings with a resolution of \(\pm 1\,\mu s\),
which is three orders of magniture greater than the one of WTF.
Finally, this event tracing tool is able to precisely trace which are the function
being called inside the Chrome's C++ code and to identify the object's class
calling that method. Therefore, it is possible to say that it is able to balance
the defects of the web tracing framework.

The grouped bar chart displayed in Figure \ref{img:no_map_groups} helped to
get an idea about the wheight each group has inside the entire response time.
Since this thesis aims at modelling the rendering pipeline of WebGL from a real-time
point of view, the focus is put only to the \emph{display} group.



\section{The mathematical model}

